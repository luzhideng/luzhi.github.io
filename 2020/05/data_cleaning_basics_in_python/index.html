<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Python," />





  <link rel="alternate" href="/atom.xml" title="Lüzhi's Notebook" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="有数据显示说，数据分析师或者数据科学家通常会花掉80%的时间去清理数据，20%的时间去分析数据和写数据报告。因为通常在真实世界当中拿到的数据往往跟在课堂中拿到的数据样本有着千差万别。真实世界的数据一般会非常的dirty，所以需要花大量的时间去清洗。一般来说，造成数据脏乱差的原因通常有两种，一是人为输入错误，而是技术原因造成的错误。不干净整洁的数据会给我们的分析造成很大的困扰，甚至会产生错误的报告从">
<meta property="og:type" content="article">
<meta property="og:title" content="Python中的基本数据清理">
<meta property="og:url" content="http://mingju.net/2020/05/data_cleaning_basics_in_python/index.html">
<meta property="og:site_name" content="Lüzhi's Notebook">
<meta property="og:description" content="有数据显示说，数据分析师或者数据科学家通常会花掉80%的时间去清理数据，20%的时间去分析数据和写数据报告。因为通常在真实世界当中拿到的数据往往跟在课堂中拿到的数据样本有着千差万别。真实世界的数据一般会非常的dirty，所以需要花大量的时间去清洗。一般来说，造成数据脏乱差的原因通常有两种，一是人为输入错误，而是技术原因造成的错误。不干净整洁的数据会给我们的分析造成很大的困扰，甚至会产生错误的报告从">
<meta property="og:image" content="http://mingju.net/uploads/images/airlines.png">
<meta property="og:image" content="http://mingju.net/uploads/images/Figure_1.png">
<meta property="og:image" content="http://mingju.net/uploads/images/Figure_2.png">
<meta property="og:image" content="http://mingju.net/uploads/images/Figure_3.png">
<meta property="og:image" content="http://mingju.net/uploads/images/Figure_4.png">
<meta property="og:image" content="http://mingju.net/uploads/images/Figure_5.png">
<meta property="og:updated_time" content="2020-05-29T00:20:05.572Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python中的基本数据清理">
<meta name="twitter:description" content="有数据显示说，数据分析师或者数据科学家通常会花掉80%的时间去清理数据，20%的时间去分析数据和写数据报告。因为通常在真实世界当中拿到的数据往往跟在课堂中拿到的数据样本有着千差万别。真实世界的数据一般会非常的dirty，所以需要花大量的时间去清洗。一般来说，造成数据脏乱差的原因通常有两种，一是人为输入错误，而是技术原因造成的错误。不干净整洁的数据会给我们的分析造成很大的困扰，甚至会产生错误的报告从">
<meta name="twitter:image" content="http://mingju.net/uploads/images/airlines.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":true},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://mingju.net/2020/05/data_cleaning_basics_in_python/"/>





  <title> Python中的基本数据清理 | Lüzhi's Notebook </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Lüzhi's Notebook</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">Harnessing Data to Drive Marketing</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://mingju.net/2020/05/data_cleaning_basics_in_python/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lüzhi Deng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lüzhi's Notebook">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
            
            
              
                Python中的基本数据清理
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-25T15:39:00+08:00">
                2020-05-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数据清洗/" itemprop="url" rel="index">
                    <span itemprop="name">数据清洗</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>有数据显示说，数据分析师或者数据科学家通常会花掉80%的时间去清理数据，20%的时间去分析数据和写数据报告。因为通常在真实世界当中拿到的数据往往跟在课堂中拿到的数据样本有着千差万别。真实世界的数据一般会非常的dirty，所以需要花大量的时间去清洗。一般来说，造成数据脏乱差的原因通常有两种，一是人为输入错误，而是技术原因造成的错误。不干净整洁的数据会给我们的分析造成很大的困扰，甚至会产生错误的报告从而影响决策。所以，当我们拿到一大堆数据的时候，第一个工作是要判断数据的来源，并且尽量的以科学的方法把数据清洗干净，然后再进行接下来的分析操作。这篇文章会分步介绍一些常见的数据清理基本操作。数据是从<a href="https://assets.datacamp.com/production/repositories/5737/datasets/ba95dfa6d750e4bf2ddda2349cfe0af80ab765ff/airlines_final.csv" target="_blank" rel="external">datacamp</a>中获取的，我在次基础上又把相对干净的数据弄脏了一些一遍举例演示，这是一个叫做airlines的csv文件，其中包含了从旧金山国际机场几天出发的航班的数据。我们先来简单的看一下airlines.csv都包含哪些数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line">df = pd.read_csv(<span class="string">'datasets/airlines.csv'</span>)</div><div class="line">df.info()</div><div class="line">df.head()</div></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">Out [1]:</div><div class="line">&lt;class 'pandas.core.frame.DataFrame'&gt;</div><div class="line">RangeIndex: 2487 entries, 0 to 2486</div><div class="line">Data columns (total 18 columns):</div><div class="line"> #   Column            Non-Null Count  Dtype  </div><div class="line">---  ------            --------------  -----  </div><div class="line"> 0   id                2487 non-null   int64  </div><div class="line"> 1   full_name         2487 non-null   object </div><div class="line"> 2   day               2487 non-null   object </div><div class="line"> 3   airline           2487 non-null   object </div><div class="line"> 4   destination       2487 non-null   object </div><div class="line"> 5   dest_region       2487 non-null   object </div><div class="line"> 6   dest_size         2487 non-null   object </div><div class="line"> 7   boarding_area     2487 non-null   object </div><div class="line"> 8   dept_time         2487 non-null   object </div><div class="line"> 9   temperature       2487 non-null   float64</div><div class="line"> 10  wait_min          2487 non-null   object </div><div class="line"> 11  cleanliness       2487 non-null   object </div><div class="line"> 12  safety            2487 non-null   object </div><div class="line"> 13  satisfaction      2487 non-null   object </div><div class="line"> 14  rating            2487 non-null   int64  </div><div class="line"> 15  frequent_flyer    2487 non-null   int64  </div><div class="line"> 16  points_gain       2487 non-null   int64  </div><div class="line"> 17  points_last_time  2487 non-null   int64  </div><div class="line"> 18  total_points      2487 non-null   int64  </div><div class="line">dtypes: float64(1), int64(6), object(12)</div><div class="line">memory usage: 369.3+ KB</div></pre></td></tr></table></figure>
<p>通过输出我们大概可以判断出这个df有id，乘客姓名，航空公司，目的地，目的地区域，登机口，起飞时间，温度，等待时间，还有一些满意度的调查，评分以及常旅和积分情况。在Spyder编译环境下，还可以看到跟Excel类似的表格，来对数据有一个更加直观的感受。</p>
<center><br><img src="http://mingju.net/uploads/images/airlines.png" alt=""><br></center>

<h1 id="数据类型问题"><a href="#数据类型问题" class="headerlink" title="数据类型问题"></a>数据类型问题</h1><p>通过df.info()以及对数据的观察，我们发现了两个数据类型。第一个是wait_min等待时间，这个数据应该是数字int或者float类型，而原来的数据是一个对象类型。第二个是frequent_flyer，我们发现数据中有0，1，2三个数字，这三个数字应该代表的是不同类型，或者不同等级的常旅会员，所以应该是category类型，而不是int类型。我们首先要做的是把这组数据类型转换成正确的数据类型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#将frequent_flyer使用astype()函数转变成category类型</span></div><div class="line">df[<span class="string">'frequent_flyer_cat'</span>] = df[<span class="string">'frequent_flyer'</span>].astype(<span class="string">'category'</span>)</div><div class="line"><span class="comment">#使用assert验证是否转换成功</span></div><div class="line"><span class="keyword">assert</span> df[<span class="string">'frequent_flyer_cat'</span>].dtype == <span class="string">'category'</span></div><div class="line">df[<span class="string">'frequent_flyer_cat'</span>].describe()</div><div class="line"><span class="comment">#使用str.strip()把wait_time中的mins字段去除，并使用astype()函数把wait_time转换成int类型</span></div><div class="line">df[<span class="string">'wait_time'</span>] = df[<span class="string">'wait_min'</span>].str.strip(<span class="string">'mins'</span>).astype(<span class="string">'int'</span>)</div><div class="line"><span class="comment">#使用assert验证是否转换成功</span></div><div class="line"><span class="keyword">assert</span> df[<span class="string">'wait_time'</span>].dtype == <span class="string">'int'</span></div></pre></td></tr></table></figure>
<p>然后我们打印一下我们清理好的wait_time这个新的变量看一下效果，然后再看一下乘客平均的等待时间：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">print(df[[<span class="string">'wait_min'</span>, <span class="string">'wait_time'</span>]])</div><div class="line">print(df[<span class="string">'wait_time'</span>].mean())</div><div class="line">Out [<span class="number">2</span>]:</div><div class="line">      wait_min  wait_time</div><div class="line"><span class="number">0</span>      <span class="number">85</span> mins         <span class="number">85</span></div><div class="line"><span class="number">1</span>      <span class="number">80</span> mins         <span class="number">80</span></div><div class="line"><span class="number">2</span>      <span class="number">75</span> mins         <span class="number">75</span></div><div class="line"><span class="number">3</span>     <span class="number">170</span> mins        <span class="number">170</span></div><div class="line"><span class="number">4</span>     <span class="number">140</span> mins        <span class="number">140</span></div><div class="line">       ...        ...</div><div class="line"><span class="number">2482</span>  <span class="number">100</span> mins        <span class="number">100</span></div><div class="line"><span class="number">2483</span>  <span class="number">124</span> mins        <span class="number">124</span></div><div class="line"><span class="number">2484</span>  <span class="number">124</span> mins        <span class="number">124</span></div><div class="line"><span class="number">2485</span>  <span class="number">335</span> mins        <span class="number">335</span></div><div class="line"><span class="number">2486</span>  <span class="number">335</span> mins        <span class="number">335</span></div><div class="line"></div><div class="line">[<span class="number">2487</span> rows x <span class="number">2</span> columns]</div><div class="line"></div><div class="line"><span class="number">165.92279855247287</span></div></pre></td></tr></table></figure>
<h1 id="数据范围问题"><a href="#数据范围问题" class="headerlink" title="数据范围问题"></a>数据范围问题</h1><p>有些时候，我们拿到的一些数据可能会出现一些数据范围错误，比如说一些当天起飞的航班日期却错误的记录成了一个未来的日期，或者某些数字超出了设置范围。例如，在airlines的rating当中，我们就发现了rating中有一些评分超出了预设范围：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">plt.hist(df[<span class="string">'rating'</span>])</div><div class="line">plt.title(<span class="string">'Average rating of satisfaction (1-5)'</span>)</div></pre></td></tr></table></figure>
<center><br><img src="http://mingju.net/uploads/images/Figure_1.png" alt=""><br></center>

<p>通过上图，我们发现了一些打分超过了1-5的评分范围。一般我们处理数据范围问题的时候通常有4种方式：</p>
<ol>
<li>简单的去除这些数据</li>
<li>设置特定的最大最小值</li>
<li>把这些超出范围的数据设置为空值并进行补全操作</li>
<li>根据特定情况为这些数据设置一个特定值</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">df[df[<span class="string">'rating'</span>] &gt; <span class="number">5</span> ] </div><div class="line">Out [<span class="number">4</span>]:</div><div class="line">      id            full_name    ...    frequent_flyer_cat  wait_time</div><div class="line"><span class="number">0</span>        <span class="number">1</span>      Dr. Neil Dunlap  ...                  <span class="number">0</span>        <span class="number">85</span></div><div class="line"><span class="number">1</span>        <span class="number">3</span>     Marquise Osborne  ...                  <span class="number">0</span>        <span class="number">80</span></div><div class="line"><span class="number">2</span>        <span class="number">4</span>  Miss. Marissa Doyle  ...                  <span class="number">0</span>        <span class="number">75</span></div><div class="line"><span class="number">3</span>        <span class="number">5</span>      Cassidy Meadows  ...                  <span class="number">1</span>       <span class="number">170</span></div><div class="line"><span class="number">4</span>        <span class="number">6</span>       Salvatore Vega  ...                  <span class="number">0</span>       <span class="number">140</span></div><div class="line"><span class="number">5</span>        <span class="number">9</span>         Darion Lopez  ...                  <span class="number">0</span>       <span class="number">110</span></div><div class="line"><span class="number">6</span>       <span class="number">10</span>           Bailee Lam  ...                  <span class="number">0</span>       <span class="number">155</span></div><div class="line"><span class="number">7</span>       <span class="number">11</span>          Reilly Koch  ...                  <span class="number">0</span>       <span class="number">200</span></div><div class="line"><span class="number">8</span>       <span class="number">12</span>           Evan Dixon  ...                  <span class="number">0</span>        <span class="number">80</span></div><div class="line"><span class="number">1458</span>  <span class="number">2107</span>       William Huerta  ...                  <span class="number">2</span>       <span class="number">100</span></div><div class="line"></div><div class="line">[<span class="number">10</span> rows x <span class="number">21</span> columns]</div></pre></td></tr></table></figure>
<p>我们发现仅仅有10个rating大于5的数据，对于一个有2000多条数据的df来说，简单的去除这些数据不会对后面的分析产生较大的影响，所以我们这里就简单的把这些数据drop掉：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#第一种drop方式：使用过滤器筛选符合条件的数据</span></div><div class="line">df = df[df[<span class="string">'rating'</span>] &lt;= <span class="number">5</span>]</div><div class="line"><span class="comment">#第二种drop方式：使用drop()函数</span></div><div class="line">df.drop(df[df[<span class="string">'rating'</span>] &gt; <span class="number">5</span>].index, inplace = <span class="keyword">True</span>)</div><div class="line"><span class="comment">#使用assert来验证是否drop完成</span></div><div class="line"><span class="keyword">assert</span> df[<span class="string">'rating'</span>].max() &lt;= <span class="number">5</span></div></pre></td></tr></table></figure>
<h1 id="数据重复问题"><a href="#数据重复问题" class="headerlink" title="数据重复问题"></a>数据重复问题</h1><p>重复的数据是一个非常常见的问题。通常造成数据重复的原因一般有三种，人为输入错误，合并数据出现的问题以及bug或者设计问题。我们可以通过<code>.duplicated()</code>函数来检查df中存在重复的数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#将会产生一个以duplicates命名的boolean series，其中所有重复的数据将会以True显示，否则为False</span></div><div class="line">duplicates = df.duplicated(subset = <span class="string">'id'</span>, keep = <span class="keyword">False</span>)</div><div class="line"><span class="comment">#选出所有重复的数据</span></div><div class="line">duplicated_passenger = df[duplicates].sort_values(<span class="string">'id'</span>)</div><div class="line">print(duplicated_passenger)</div><div class="line"></div><div class="line">Out [<span class="number">5</span>]:</div><div class="line">       id             full_name  ... frequent_flyer_cat   wait_time</div><div class="line"><span class="number">2467</span>  <span class="number">3286</span>           Lilly Wong  ...                  <span class="number">1</span>        <span class="number">95</span></div><div class="line"><span class="number">2468</span>  <span class="number">3286</span>           Lilly Wong  ...                  <span class="number">1</span>        <span class="number">95</span></div><div class="line"><span class="number">2469</span>  <span class="number">3287</span>         Prince Poole  ...                  <span class="number">0</span>        <span class="number">65</span></div><div class="line"><span class="number">2470</span>  <span class="number">3287</span>         Prince Poole  ...                  <span class="number">0</span>        <span class="number">65</span></div><div class="line"><span class="number">2471</span>  <span class="number">3288</span>           Koen Meyer  ...                  <span class="number">0</span>        <span class="number">85</span></div><div class="line"><span class="number">2472</span>  <span class="number">3288</span>           Koen Meyer  ...                  <span class="number">0</span>        <span class="number">85</span></div><div class="line"><span class="number">2473</span>  <span class="number">3289</span>  Christian Blackburn  ...                  <span class="number">0</span>        <span class="number">95</span></div><div class="line"><span class="number">2474</span>  <span class="number">3289</span>  Christian Blackburn  ...                  <span class="number">0</span>        <span class="number">95</span></div><div class="line"><span class="number">2476</span>  <span class="number">3291</span>    Lindsay Valentine  ...                  <span class="number">0</span>        <span class="number">95</span></div><div class="line"><span class="number">2475</span>  <span class="number">3291</span>    Lindsay Valentine  ...                  <span class="number">0</span>        <span class="number">95</span></div><div class="line"><span class="number">2477</span>  <span class="number">3292</span>       Johnny Mueller  ...                  <span class="number">0</span>       <span class="number">145</span></div><div class="line"><span class="number">2478</span>  <span class="number">3292</span>       Johnny Mueller  ...                  <span class="number">0</span>       <span class="number">120</span></div><div class="line"><span class="number">2479</span>  <span class="number">9001</span>          Devyn Rocha  ...                  <span class="number">0</span>       <span class="number">135</span></div><div class="line"><span class="number">2480</span>  <span class="number">9001</span>          Devyn Rocha  ...                  <span class="number">0</span>       <span class="number">135</span></div><div class="line"><span class="number">2481</span>  <span class="number">9002</span>            Zoe Payne  ...                  <span class="number">0</span>       <span class="number">120</span></div><div class="line"><span class="number">2482</span>  <span class="number">9002</span>            Zoe Payne  ...                  <span class="number">0</span>       <span class="number">120</span></div><div class="line"><span class="number">2483</span>  <span class="number">9003</span>        Karley Burton  ...                  <span class="number">1</span>       <span class="number">124</span></div><div class="line"><span class="number">2484</span>  <span class="number">9003</span>        Karley Burton  ...                  <span class="number">1</span>       <span class="number">124</span></div><div class="line"><span class="number">2485</span>  <span class="number">9004</span>    Evangeline Flores  ...                  <span class="number">2</span>       <span class="number">335</span></div><div class="line"><span class="number">2486</span>  <span class="number">9004</span>    Evangeline Flores  ...                  <span class="number">2</span>       <span class="number">335</span></div></pre></td></tr></table></figure>
<p>通过对以上重复的数据观察，我们发现大部分重复的数据为完全重复，就是一模一样的数据出现了两条或两条以上，对于这种情况，我们简单的使用<code>.drop_duplicates()</code>函数把重复的数据保留下来一条就可以了。但是数据中那些不是完全重复的情况我们需要进一步对其处理，比如以上重复数据中就出现了一对不完全重复的数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"> id            		  full_name  ... 	frequent_flyer_cat  wait_time</div><div class="line"><span class="number">2477</span>  <span class="number">3292</span>       Johnny Mueller  ...                  <span class="number">0</span>       <span class="number">145</span></div><div class="line"><span class="number">2478</span>  <span class="number">3292</span>       Johnny Mueller  ...                  <span class="number">0</span>       <span class="number">120</span></div></pre></td></tr></table></figure>
<p>这一对数据中其他数据一模一样，但是在wait_time中出现了差别。对于这种差异我们可以根据出现的实际情况进行评估，然后对数据进行impute。以上这种情况，我们可以简单的取两次wait_time的平均值即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#我们首先把完全重复的数据drop掉</span></div><div class="line">pass_dup = df.drop_duplicates()</div><div class="line"><span class="comment">#为agg()创建统计字典</span></div><div class="line">column_names = [<span class="string">'id'</span>]</div><div class="line">statistics = &#123;<span class="string">'wait_time'</span>: <span class="string">'mean'</span>&#125;</div><div class="line">df_wt = pass_dup.groupby(by = column_names).agg(statistics).reset_index()</div><div class="line"><span class="comment">#把agg()操作过的df_wt与之前去过重的pass_dup合并</span></div><div class="line">df = pd.merge(df_wt, pass_dup, on=<span class="string">'id'</span>)</div></pre></td></tr></table></figure>
<p>在合并这两个df之后，我们需要再对数据进行一次查重操作，因为merge的过程是有可能产生重复数据的，尤其是inner merge:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">duplicates = df.duplicated(subset = column_names, keep = <span class="keyword">False</span>)</div><div class="line">duplicated_passenger = df[duplicates == <span class="keyword">True</span>]</div><div class="line">print(duplicated_passenger)</div><div class="line">Out [<span class="number">6</span>]:</div><div class="line">        id  wait_time_x  ... frequent_flyer_cat wait_time_y</div><div class="line"><span class="number">2462</span>  <span class="number">3292</span>        <span class="number">132.5</span>  ...                  <span class="number">0</span>         <span class="number">145</span></div><div class="line"><span class="number">2463</span>  <span class="number">3292</span>        <span class="number">132.5</span>  ...                  <span class="number">0</span>         <span class="number">120</span></div></pre></td></tr></table></figure>
<p>我们发现由于merge操作df中又出现了数据重复的情况，原因是因为在我们合并的过程中，由于wait_time在pass_dup中有两个值145和120。所以我们只需要留一条数据即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#根据id去除重复数据并且保留重复数据的第一条数据</span></div><div class="line">df = df.drop_duplicates(subset = <span class="string">'id'</span>, keep = <span class="string">'first'</span>)</div><div class="line"></div><div class="line"><span class="comment">#重新检查是否还存在重复的数据</span></div><div class="line">duplicates = df.duplicated(subset = column_names, keep = <span class="keyword">False</span>)</div><div class="line">duplicated_passenger = df[duplicates == <span class="keyword">True</span>]</div><div class="line">print(duplicated_passenger)</div><div class="line">Out [<span class="number">7</span>]:</div><div class="line">Empty DataFrame</div><div class="line">Columns: [id, wait_time_x, full_name, day, airline, destination, dest_region, dest_size, boarding_area, dept_time, temperature, wait_min, cleanliness, safety, satisfaction, rating, frequent_flyer, points_gain, points_last_time, total_points, frequent_flyer_cat, wait_time_y]</div><div class="line">Index: []</div><div class="line"><span class="comment">#验证重复数据是否被去除</span></div><div class="line"><span class="keyword">assert</span> duplicated_passenger.shape[<span class="number">0</span>] == <span class="number">0</span></div><div class="line"><span class="comment">#删除多余的wait_time_y列，重新命名wait_time_x列</span></div><div class="line">df = df.drop(<span class="string">'wait_time_y'</span>, axis = <span class="number">1</span>)</div><div class="line">df = df.rename(columns = &#123;<span class="string">'wait_time_x'</span>: <span class="string">'wait_time'</span>&#125;)</div></pre></td></tr></table></figure>
<p>通过打印和assert验证，我们发现已经没有重复的数据了。</p>
<h1 id="分类数据问题"><a href="#分类数据问题" class="headerlink" title="分类数据问题"></a>分类数据问题</h1><p>在分类变量中通常也会出现数据分类错误的问题，例如在采集数据的时候会出现类别输入错误。一般我们处理这类数据问题时，有三种处理方法。</p>
<ol>
<li>去除这些数据</li>
<li>对这些数据进行重新映射</li>
<li>根据实际情况进行数据推理</li>
</ol>
<p>在airlines数据中的评价数据<code>cleanliness</code>中也出现了分类数据的问题。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#先对cleanliness，safety和satisfaction三类数据指定评价范围categories数据框，在接下来进行比较</span></div><div class="line">categories = pd.DataFrame(&#123;<span class="string">'cleanliness'</span>: [<span class="string">"Clean"</span>, <span class="string">"Average"</span>, <span class="string">"Somewhat clean"</span>, \</div><div class="line">              <span class="string">"Somewhat dirty"</span>, <span class="string">"Dirty"</span>],</div><div class="line">              <span class="string">'safty'</span>: [<span class="string">"Neutral"</span>, <span class="string">"Very safe"</span>, <span class="string">"Somewhat safe"</span>, \</div><div class="line">              <span class="string">"Very unsafe"</span>, <span class="string">"Somewhat unsafe"</span>],</div><div class="line">              <span class="string">'satisfaction'</span>: [<span class="string">"Very satisfied"</span>, <span class="string">"Neutral"</span>, \</div><div class="line">              <span class="string">"Somewhat satisfied"</span>, <span class="string">"Somewhat unsatisfied"</span>, <span class="string">"Very unsatisfied"</span>]&#125;)</div><div class="line">print(categories) </div><div class="line">Out [<span class="number">8</span>]:</div><div class="line">		cleanliness         safty          satisfaction</div><div class="line"><span class="number">0</span>           Clean          Neutral        Very satisfied</div><div class="line"><span class="number">1</span>         Average        Very safe               Neutral</div><div class="line"><span class="number">2</span>  Somewhat clean    Somewhat safe    Somewhat satisfied</div><div class="line"><span class="number">3</span>  Somewhat dirty      Very unsafe  Somewhat unsatisfied</div><div class="line"><span class="number">4</span>           Dirty  Somewhat unsafe      Very unsatisfied</div></pre></td></tr></table></figure>
<p>每个变量中有5个评分标准，接下来检查数据中是否有评分标准不在这15个评分标准中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">print(<span class="string">'Cleanliness: '</span>, df[<span class="string">'cleanliness'</span>].unique(), <span class="string">"\n"</span>)</div><div class="line">print(<span class="string">'Safety: '</span>, df[<span class="string">'safety'</span>].unique(), <span class="string">"\n"</span>)</div><div class="line">print(<span class="string">'Satisfaction: '</span>, df[<span class="string">'satisfaction'</span>].unique(), <span class="string">"\n"</span>)</div><div class="line">Out [<span class="number">9</span>]:</div><div class="line">Cleanliness:  [<span class="string">'Average'</span> <span class="string">'Unacceptable'</span> <span class="string">'Somewhat clean'</span> <span class="string">'Clean'</span> <span class="string">'Somewhat dirty'</span></div><div class="line"> <span class="string">'Dirty'</span>] </div><div class="line"></div><div class="line">Safety:  [<span class="string">'Somewhat safe'</span> <span class="string">'Very safe'</span> <span class="string">'Neutral'</span> <span class="string">'Somewhat unsafe'</span> <span class="string">'Very unsafe'</span>] </div><div class="line"></div><div class="line">Satisfaction:  [<span class="string">'Somewhat satsified'</span> <span class="string">'Neutral'</span> <span class="string">'Very satisfied'</span> <span class="string">'Somewhat unsatisfied'</span></div><div class="line"> <span class="string">'Very unsatisfied'</span>]</div></pre></td></tr></table></figure>
<p>在<code>cleanliness</code>，出现了一个Unacceptable的评分，这个评分超出了我们预设的标准<code>categories</code>，所以需要对它进行一定的处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#使用set()函数取出从cleanliness中唯一的值，然后用difference()函数判断哪个值不在预设评分标准categories中</span></div><div class="line">cat_clean = set(df[<span class="string">'cleanliness'</span>]).difference(categories[<span class="string">'cleanliness'</span>])</div><div class="line"><span class="comment">#取出评分不在预设评分标准中的数据</span></div><div class="line">cat_clean_rows = df[<span class="string">'cleanliness'</span>].isin(cat_clean)</div><div class="line"><span class="comment">#打印不在评分标准中的数据</span></div><div class="line">print(df[cat_clean_rows])</div><div class="line">Out [<span class="number">10</span>]:</div><div class="line">  id  wait_time     ... total_points        frequent_flyer_cat</div><div class="line"><span class="number">2</span>   <span class="number">100</span>      <span class="number">120.0</span>  ...            <span class="number">0</span>                  <span class="number">0</span></div><div class="line"><span class="number">42</span>  <span class="number">257</span>      <span class="number">205.0</span>  ...          <span class="number">838</span>                  <span class="number">2</span></div><div class="line"></div><div class="line">[<span class="number">2</span> rows x <span class="number">21</span> columns]</div><div class="line"><span class="comment">#打印在评分标准中的数据</span></div><div class="line">print(df[~cat_clean_rows])</div><div class="line">Out [<span class="number">11</span>]:</div><div class="line"> id  wait_time  	   ... total_points        frequent_flyer_cat</div><div class="line"><span class="number">0</span>       <span class="number">13</span>       <span class="number">90.0</span>  ...            <span class="number">0</span>                  <span class="number">0</span></div><div class="line"><span class="number">1</span>       <span class="number">14</span>       <span class="number">89.0</span>  ...          <span class="number">989</span>                  <span class="number">1</span></div><div class="line"><span class="number">3</span>      <span class="number">101</span>      <span class="number">140.0</span>  ...          <span class="number">390</span>                  <span class="number">2</span></div><div class="line"><span class="number">4</span>      <span class="number">102</span>      <span class="number">200.0</span>  ...         <span class="number">1816</span>                  <span class="number">1</span></div><div class="line"><span class="number">5</span>      <span class="number">103</span>      <span class="number">130.0</span>  ...          <span class="number">832</span>                  <span class="number">1</span></div><div class="line">   ...        ...  ...          ...                ...</div><div class="line"><span class="number">2462</span>  <span class="number">3292</span>      <span class="number">132.5</span>  ...            <span class="number">0</span>                  <span class="number">0</span></div><div class="line"><span class="number">2464</span>  <span class="number">9001</span>      <span class="number">135.0</span>  ...            <span class="number">0</span>                  <span class="number">0</span></div><div class="line"><span class="number">2465</span>  <span class="number">9002</span>      <span class="number">120.0</span>  ...            <span class="number">0</span>                  <span class="number">0</span></div><div class="line"><span class="number">2466</span>  <span class="number">9003</span>      <span class="number">124.0</span>  ...         <span class="number">1244</span>                  <span class="number">1</span></div><div class="line"><span class="number">2467</span>  <span class="number">9004</span>      <span class="number">335.0</span>  ...         <span class="number">1322</span>                  <span class="number">2</span></div><div class="line"></div><div class="line">[<span class="number">2465</span> rows x <span class="number">21</span> columns]</div><div class="line"></div><div class="line"><span class="comment">#保留所有符合评分标准的数据到df中</span></div><div class="line">df = df[~cat_clean_rows]</div></pre></td></tr></table></figure>
<p>在浏览数据的过程当中<code>dest_region</code>出现了字母大小写不统一，相同数据使用不同分类标记的现象，在<code>dest_size</code>中看到了数据有空格的现象。这些问题python都会把他们当作不同的类别来处理，但是实际上有一些数据的类别是相同的，只是由于各种各样的原因，造成了一些数据错误的录入，所以需要对它们也进行清理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#首先打印出这两个变量下的唯一值，并且使用value_counts()函数观察一下不同类别的数量</span></div><div class="line">print(df[<span class="string">'dest_region'</span>].unique())</div><div class="line">print(df[<span class="string">'dest_region'</span>].value_counts())</div><div class="line">print(df[<span class="string">'dest_size'</span>].unique())</div><div class="line">print(df[<span class="string">'dest_size'</span>].value_counts())</div><div class="line"></div><div class="line">Out [<span class="number">12</span>]:</div><div class="line"></div><div class="line">[<span class="string">'West US'</span> <span class="string">'EAST US'</span> <span class="string">'Midwest US'</span> <span class="string">'Canada/Mexico'</span> <span class="string">'East US'</span> <span class="string">'eur'</span> <span class="string">'Europe'</span></div><div class="line"> <span class="string">'middle east'</span> <span class="string">'Middle East'</span> <span class="string">'Asia'</span> <span class="string">'Central/South America'</span></div><div class="line"> <span class="string">'Australia/New Zealand'</span>]</div><div class="line">West US                  <span class="number">855</span></div><div class="line">East US                  <span class="number">367</span></div><div class="line">Europe                   <span class="number">272</span></div><div class="line">Midwest US               <span class="number">251</span></div><div class="line">Asia                     <span class="number">226</span></div><div class="line">Canada/Mexico            <span class="number">196</span></div><div class="line">eur                       <span class="number">79</span></div><div class="line">EAST US                   <span class="number">68</span></div><div class="line">Australia/New Zealand     <span class="number">60</span></div><div class="line">Middle East               <span class="number">48</span></div><div class="line">Central/South America     <span class="number">22</span></div><div class="line">middle east               <span class="number">21</span></div><div class="line">Name: dest_region, dtype: int64</div><div class="line">        </div><div class="line">[<span class="string">'Hub'</span> <span class="string">'Medium     '</span> <span class="string">'    Medium'</span> <span class="string">'    Hub'</span> <span class="string">'Hub     '</span> <span class="string">'Medium'</span></div><div class="line"> <span class="string">'Small     '</span> <span class="string">'    Small'</span> <span class="string">'Small'</span> <span class="string">'Large     '</span> <span class="string">'    Large'</span> <span class="string">'Large'</span>]</div><div class="line">Hub            <span class="number">1197</span></div><div class="line">Medium          <span class="number">457</span></div><div class="line">    Hub         <span class="number">222</span></div><div class="line">Small           <span class="number">165</span></div><div class="line">Hub             <span class="number">121</span></div><div class="line">Large           <span class="number">110</span></div><div class="line">    Medium       <span class="number">96</span></div><div class="line">Medium           <span class="number">45</span></div><div class="line">    Small        <span class="number">20</span></div><div class="line">Small            <span class="number">15</span></div><div class="line">    Large        <span class="number">11</span></div><div class="line">Large             <span class="number">6</span></div><div class="line">Name: dest_size, dtype: int64</div></pre></td></tr></table></figure>
<p>在<code>dest_region</code>中，我们看到python把<code>East US</code>和<code>EAST US</code>，<code>Middle East</code>和<code>middle east</code>，<code>Europe</code>和<code>eur</code>当作了不同的类别来处理，我们知道他们其实应该是相同的类别。类似的问题出现在了<code>dest_size</code>中，python同样把前面有空格的类别和没有空格的类别当作了不同的类别。我们需要对这些问题数据进行处理，其中关于<code>dest_region</code>的问题，我们可以把所有的类别名称全部换成大写<code>.str.upper()</code>或者小写<code>.str.lower()</code>，然后把<code>eur</code>替换成<code>europe</code>即可。在<code>dest_size</code>中，我们可以把空格去除便可解决问题：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#将dest_region列中的数据字母全部改为小写</span></div><div class="line">df[<span class="string">'dest_region'</span>] = df[<span class="string">'dest_region'</span>].str.lower()</div><div class="line"><span class="comment">#替换'eur'为'europe'</span></div><div class="line">df[<span class="string">'dest_region'</span>] = df[<span class="string">'dest_region'</span>].replace(&#123;<span class="string">'eur'</span>:<span class="string">'europe'</span>&#125;)</div><div class="line"><span class="comment">#去除dest_size中的空格</span></div><div class="line">df[<span class="string">'dest_size'</span>] = df[<span class="string">'dest_size'</span>].str.strip()</div><div class="line"><span class="comment">#再次打印观察分类数据的情况</span></div><div class="line">print(df[<span class="string">'dest_region'</span>].unique())</div><div class="line">print(df[<span class="string">'dest_region'</span>].value_counts())</div><div class="line">print(df[<span class="string">'dest_size'</span>].unique())</div><div class="line">print(df[<span class="string">'dest_size'</span>].value_counts())</div><div class="line"></div><div class="line">Out [<span class="number">13</span>]:</div><div class="line">[<span class="string">'west us'</span> <span class="string">'east us'</span> <span class="string">'midwest us'</span> <span class="string">'canada/mexico'</span> <span class="string">'europe'</span> <span class="string">'middle east'</span></div><div class="line"> <span class="string">'asia'</span> <span class="string">'central/south america'</span> <span class="string">'australia/new zealand'</span>]</div><div class="line">west us                  <span class="number">855</span></div><div class="line">east us                  <span class="number">435</span></div><div class="line">europe                   <span class="number">351</span></div><div class="line">midwest us               <span class="number">251</span></div><div class="line">asia                     <span class="number">226</span></div><div class="line">canada/mexico            <span class="number">196</span></div><div class="line">middle east               <span class="number">69</span></div><div class="line">australia/new zealand     <span class="number">60</span></div><div class="line">central/south america     <span class="number">22</span></div><div class="line">Name: dest_region, dtype: int64</div><div class="line">[<span class="string">'Hub'</span> <span class="string">'Medium'</span> <span class="string">'Small'</span> <span class="string">'Large'</span>]</div><div class="line">Hub       <span class="number">1540</span></div><div class="line">Medium     <span class="number">598</span></div><div class="line">Small      <span class="number">200</span></div><div class="line">Large      <span class="number">127</span></div><div class="line">Name: dest_size, dtype: int64</div></pre></td></tr></table></figure>
<p>有时候我们需要更直观的表现一些分类数据的时候，需要为一些数据进行分组，比如说wait_time这个变量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">plt.hist(x = <span class="string">'wait_time'</span>, data = df)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<center><br><img src="http://mingju.net/uploads/images/Figure_2.png" alt=""><br></center>

<p>可以看出大部分人的等待时间是在0-300分钟之间，如果我们对等待时间进行分组，分别分成等待时间较短（short），等待时间适中（medium）和等待时间较长（long）我们可以这样操作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#设置范围0-60，60-180，180-无限三个分组</span></div><div class="line">label_ranges = [<span class="number">0</span>, <span class="number">60</span>, <span class="number">180</span>, np.inf]</div><div class="line"><span class="comment">#三个分组分别对应的类别名称</span></div><div class="line">label_names = [<span class="string">'short'</span>, <span class="string">'medium'</span>, <span class="string">'long'</span>]</div><div class="line"><span class="comment">#对wait_time进行分组</span></div><div class="line">df[<span class="string">'wait_type'</span>] = pd.cut(df[<span class="string">'wait_time'</span>], bins = label_ranges, </div><div class="line">                                labels = label_names)</div><div class="line"></div><div class="line">plt.hist(x = <span class="string">'wait_type'</span>, data = df)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<center><br><img src="http://mingju.net/uploads/images/Figure_3.png" alt=""><br></center>

<p>除了可以根据数据划分组别，我们还可以重新映射数据，比如说我们可以把<code>day</code>变量的星期几重新映射成工作日（weekday）和周末（weekend）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">mappings = &#123;<span class="string">'Monday'</span>:<span class="string">'weekday'</span>, <span class="string">'Tuesday'</span>:<span class="string">'weekday'</span>, <span class="string">'Wednesday'</span>: <span class="string">'weekday'</span>, </div><div class="line">            <span class="string">'Thursday'</span>: <span class="string">'weekday'</span>, <span class="string">'Friday'</span>: <span class="string">'weekday'</span>, </div><div class="line">            <span class="string">'Saturday'</span>: <span class="string">'weekend'</span>, <span class="string">'Sunday'</span>: <span class="string">'weekend'</span>&#125;</div><div class="line"></div><div class="line">df[<span class="string">'day_week'</span>] = df[<span class="string">'day'</span>].replace(mappings)</div></pre></td></tr></table></figure>
<h1 id="文本数据清理"><a href="#文本数据清理" class="headerlink" title="文本数据清理"></a>文本数据清理</h1><p>full_name变量中的姓名中有个别数据出现了一些敬称如Dr. Mr. Ms. Miss.等，我们为了使得数据变得统一，可以把这些敬称去除：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">df[<span class="string">'full_name'</span>] = df[<span class="string">'full_name'</span>].str.replace(<span class="string">'Dr.'</span>, <span class="string">''</span>).str.replace(<span class="string">'Mr.'</span>, <span class="string">''</span>)\</div><div class="line">    .str.replace(<span class="string">'Ms.'</span>, <span class="string">''</span>).str.replace(<span class="string">'Miss.'</span>, <span class="string">''</span>).str.strip()</div><div class="line"><span class="comment"># 验证数据里是否还存在已经去除的敬称</span></div><div class="line"><span class="keyword">assert</span> df[<span class="string">'full_name'</span>].str.contains(<span class="string">'Ms.|Mr.|Miss|Dr.'</span>).any() == <span class="keyword">False</span></div></pre></td></tr></table></figure>
<p>关于文本数据清理，可能会在实际情况中遇到更多的问题，多数情况我们需要使用replace()函数进行替换或者删除文本，同时在清理更加复杂的文本数据的时候还会用到正则表达式。</p>
<h1 id="格式统一问题"><a href="#格式统一问题" class="headerlink" title="格式统一问题"></a>格式统一问题</h1><center><br><img src="http://mingju.net/uploads/images/Figure_4.png" alt=""><br></center>

<p>数据的格式统一性也是经常出现的问题，例如在airlines中，起飞日期dept_time的数据中就出现了日期格式不统一的问题，甚至出现了13/31/2018这种不存在的日期：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#我们首先把dept_time转换成合适的数据类型datetime类型</span></div><div class="line">df[<span class="string">'dept_time_dt'</span>] = pd.to_datetime(df[<span class="string">'dept_time'</span>])</div></pre></td></tr></table></figure>
<p>出现了报错：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">DateParseError: Invalid date specified (<span class="number">13</span>/<span class="number">31</span>)</div></pre></td></tr></table></figure>
<p>因为日期类型超出了范围，所以pandas抛出一个DateParseError错误，我们可以在<code>pd.to_datetime()</code>函数中增加一个<code>errors</code>参数来解决这个问题：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">df[<span class="string">'dept_time_dt'</span>] = pd.to_datetime(df[<span class="string">'dept_time'</span>],\</div><div class="line">                                    infer_datetime_format = <span class="keyword">True</span>, \</div><div class="line">                                    errors = <span class="string">'coerce'</span>)</div></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line">df.info()</div><div class="line">Out [14]:</div><div class="line">&lt;class 'pandas.core.frame.DataFrame'&gt;</div><div class="line">Int64Index: 2465 entries, 0 to 2467</div><div class="line">Data columns (total 24 columns):</div><div class="line"> #   Column              Non-Null Count  Dtype         </div><div class="line">---  ------              --------------  -----         </div><div class="line"> 0   id                  2465 non-null   int64         </div><div class="line"> 1   wait_time           2465 non-null   float64       </div><div class="line"> 2   full_name           2465 non-null   object        </div><div class="line"> 3   day                 2465 non-null   object        </div><div class="line"> 4   airline             2465 non-null   object        </div><div class="line"> 5   destination         2465 non-null   object        </div><div class="line"> 6   dest_region         2465 non-null   object        </div><div class="line"> 7   dest_size           2465 non-null   object        </div><div class="line"> 8   boarding_area       2465 non-null   object        </div><div class="line"> 9   dept_time           2465 non-null   object        </div><div class="line"> 10  temperature         2465 non-null   float64       </div><div class="line"> 11  wait_min            2465 non-null   object        </div><div class="line"> 12  cleanliness         2465 non-null   object        </div><div class="line"> 13  safety              2465 non-null   object        </div><div class="line"> 14  satisfaction        2465 non-null   object        </div><div class="line"> 15  rating              2465 non-null   int64         </div><div class="line"> 16  frequent_flyer      2465 non-null   int64         </div><div class="line"> 17  points_gain         2465 non-null   int64         </div><div class="line"> 18  points_last_time    2465 non-null   int64         </div><div class="line"> 19  total_points        2465 non-null   int64         </div><div class="line"> 20  frequent_flyer_cat  2465 non-null   category      </div><div class="line"> 21  wait_type           2465 non-null   category      </div><div class="line"> 22  day_week            2465 non-null   object        </div><div class="line"> 23  dept_time_dt        2464 non-null   datetime64[ns]</div><div class="line">dtypes: category(2), datetime64[ns](1), float64(2), int64(6), object(13)</div><div class="line">memory usage: 447.9+ KB</div><div class="line">df.head()</div><div class="line">Out [15]:</div><div class="line">  id  wait_time       full_name    ... wait_type day_week dept_time_dt</div><div class="line">0   13       90.0     Krista Leon  ...    medium  weekday          NaT</div><div class="line">1   14       89.0  Andrew Salazar  ...    medium  weekday   2018-12-31</div><div class="line">3  101      140.0  Kelvin Richard  ...    medium  weekday   2018-12-31</div><div class="line">4  102      200.0    Kylan Harper  ...      long  weekday   2018-12-31</div><div class="line">5  103      130.0      Cesar Lang  ...    medium  weekday   2018-12-31</div><div class="line"></div><div class="line">[5 rows x 24 columns]</div></pre></td></tr></table></figure>
<p>这时<code>dept_time_dt</code>变量已经变为了<code>datetime64[ns]</code>类型，并且<code>infer_datetime_format = True</code>参数把December 31st, 2018映射成了2018-12-31跟其他数据统一的格式。13/31/2018这个日期程序无法映射和判断其到底为哪天，所以它被赋值为了NaT。</p>
<p>在<code>dept_time_dt</code>中还出现了一些当天起飞的航班日期被标记成了未来的日期，我们把这些日期进行一些处理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#获取今天的日期</span></div><div class="line">today = pd.to_datetime(<span class="string">'today'</span>).floor(<span class="string">'D'</span>)</div><div class="line"><span class="comment">#选取`dept_time_dt`中大于今天日期的数据，把其日期设置为今天的日期</span></div><div class="line">df.loc[df[<span class="string">'dept_time_dt'</span>] &gt; today, <span class="string">'dept_time_dt'</span>] = today</div><div class="line"><span class="comment">#打印出目前数据中最大的日期</span></div><div class="line">print(df[<span class="string">'dept_time_dt'</span>].max())</div></pre></td></tr></table></figure>
<p>到目前为止，我们几乎对所有变量都进行了一定的清理，未被清理的数据也就只剩下个别的变量了。接下来我们来看一下<code>temperature</code>这个变量的数据有没有问题：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">plt.scatter(x = <span class="string">'dept_time_dt'</span>, y = <span class="string">'temperature'</span>, data = df)</div><div class="line"><span class="comment"># Create title, xlabel and ylabel</span></div><div class="line">plt.title(<span class="string">'Temperature in Fahrenheit - SFO'</span>)</div><div class="line">plt.xlabel(<span class="string">'Dates'</span>)</div><div class="line">plt.ylabel(<span class="string">'Temperature in Fahrenheit'</span>)</div><div class="line">plt.xticks(rotation = <span class="number">90</span>)</div><div class="line"><span class="comment"># Show plot</span></div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<center><br><img src="http://mingju.net/uploads/images/Figure_5.png" alt=""><br></center>

<p>通过散点图发现了2018年1月和2019年1月有出现了一些极寒的温度，在旧金山这种地方不太会出现10华氏度左右的问题，通过常识判断，应该是10摄氏度，我们对小于20的温度值进行温度转换：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">temp_cel = df.loc[df[<span class="string">'temperature'</span>] &lt; <span class="number">20</span>, <span class="string">'temperature'</span>]</div><div class="line"><span class="comment">#摄氏度转华氏度公式</span></div><div class="line">temp_fah = <span class="number">1.8</span> * temp_cel + <span class="number">32</span></div><div class="line">df.loc[df[<span class="string">'temperature'</span>] &lt; <span class="number">20</span>, <span class="string">'temperature'</span>] = temp_fah</div><div class="line"><span class="comment">#验证数据是否还存在最小值低于20的情况</span></div><div class="line"><span class="keyword">assert</span> df[<span class="string">'temperature'</span>].min() &gt; <span class="number">20</span></div></pre></td></tr></table></figure>
<h1 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h1><p>最后我们对常旅会员的积分进行交叉验证，看是否存在积分不对等的情况。关于积分一共有三个变量，分别是本次飞行获得的积分（points_gain），本次飞行之前的基本（points_last_time），还有总积分(total_points)。</p>
<p>所以，total_points = points_gain + points_last_time</p>
<p>我们来验证一下是否如此：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">points_col = [<span class="string">'points_gain'</span>, <span class="string">'points_last_time'</span>]</div><div class="line">points_equ = df[points_col].sum(axis=<span class="number">1</span>) == df[<span class="string">'total_points'</span>]</div><div class="line">consistent_points = df[points_equ]</div><div class="line">inconsistent_points = df[~points_equ]</div><div class="line">print(<span class="string">"Number of inconsistent points: "</span>, inconsistent_points.shape[<span class="number">0</span>])</div><div class="line"></div><div class="line">Out [<span class="number">16</span>]:</div><div class="line">Number of inconsistent points:  <span class="number">1</span></div></pre></td></tr></table></figure>
<p>发现了存在1个不相等的数据。一般来讲，当我们发现了这种不前后矛盾的数据之后，最简单的办法就是drop，或者我们可以设置为NA空值，然后对其进行impute。我们的例子中的这种情况处理办法比较简单，可以就矛盾的数据拿出来检查，然后看是哪里出了问题，然后进行处理即可。</p>
<p>借此，我们对airlines这个df的数据清洗就到此为止了，接下来我们就可以对此进行分析了。</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Python/" rel="tag"># Python</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/05/taobao_crawler/" rel="next" title="淘宝商品比价定向爬虫【MOOC实例微优化】">
                <i class="fa fa-chevron-left"></i> 淘宝商品比价定向爬虫【MOOC实例微优化】
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/05/dealing_with_missing_data_in_python/" rel="prev" title="Python中的缺失数据处理方法">
                Python中的缺失数据处理方法 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

          
          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="Lüzhi Deng" />
          <p class="site-author-name" itemprop="name">Lüzhi Deng</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">41</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://www.linkedin.com/in/luzhideng/" target="_blank" title="Linkedin">
                  
                    <i class="fa fa-fw fa-linkedin"></i>
                  
                  Linkedin
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/luzhideng" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#数据类型问题"><span class="nav-text">数据类型问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#数据范围问题"><span class="nav-text">数据范围问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#数据重复问题"><span class="nav-text">数据重复问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分类数据问题"><span class="nav-text">分类数据问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#文本数据清理"><span class="nav-text">文本数据清理</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#格式统一问题"><span class="nav-text">格式统一问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#交叉验证"><span class="nav-text">交叉验证</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2012 - 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-git"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Lüzhi Deng</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    
    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  





  



  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  

  

  


  

</body>
</html>
